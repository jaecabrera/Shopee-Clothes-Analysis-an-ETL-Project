# -*- coding: utf-8 -*-
"""shopee-shops-FINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nbM3qKXuPUxGA9zM3KHs_hU_2WdRPzM9
"""

import pandas as pd
from datetime import datetime
from loader.datafarm import DataFarmer
from time import ctime
import numpy as np
import warnings

warnings.filterwarnings(action='ignore')
OUTPUT_FILEPATH = "E:\\cj-files\\Shopee ETL\\Global Output\\"

df = DataFarmer(
    filepath=r'E:\cj-files\Shopee ETL\Global Input',
    date='None')

# create list of those files
files = [items for items in df.data_directory()]

# find the updated files for this date
for item in files:
    if 'shop' in item:
        if item.startswith(df.time()) & item.endswith('.json'):
            shop_df = pd.read_json(df.filepath + '\\' + item)

# copy shop dataframe to var data
data = shop_df.copy(deep=True)

# drop na shops
data.dropna(inplace=True)

# get json data as list
json_list = []
for json_object in data.shop_data[:]:
    json_list.append(json_object)

# normalize data into 1 dataframe
shop_normalize_data = pd.json_normalize(json_list)
shop_normalize_data.head()

# get needed features
shop_data = shop_normalize_data[[
    'shopid',
    'ctime',
    'name',
    'item_count',
    'follower_count',
    'response_rate',
    'response_time',
    'shop_location',
    'is_shopee_verified',
    'is_official_shop',
    'rating_bad',
    'rating_good',
    'rating_normal',
    'rating_star',
]]

shop_data.head(10)

"""**SHOP LOCATION NULL VALUES**"""

# get empty shop location with empty string
null_shop_data = shop_data.query("shop_location == ''").copy(deep=True)

# replace empty string with null values
null_shop_data.shop_location = np.nan

# get indexes of these null values
null_shop_location_indexes = np.asarray(null_shop_data.index)

# match and replace values in shop data
shop_data.iloc[null_shop_location_indexes] = null_shop_data

# convert boolean to (0,1) int values
shop_data[['is_shopee_verified', 'is_official_shop']] = shop_data[
    ['is_shopee_verified', 'is_official_shop']].astype('int')

# convert ctime column to time string
time_data = shop_data['ctime'].apply(lambda time: ctime(time))

# convert string to datetime object
time_data = pd.to_datetime(time_data)
shop_data['ctime'] = time_data

"""**RESPONSE TIME**"""

# check possible missing values for response_time
no_response_time = shop_data['response_time'].isna().sum()
null_ratio_no_response_time = no_response_time / len(shop_data)

# add dict for info
shop_data_info = {
    'shape': shop_data.shape,
    'response_time_missing': no_response_time,
    'shape_to_null_ratio': null_ratio_no_response_time,
}

# add user warning
if null_ratio_no_response_time >= 0.15:
    warnings.warn("Response Time: NULL values exceed 15% ")
    print(f'{shop_data_info}')

# response time null values
shop_data_nulls = list(shop_data[shop_data.response_time.isna()].index)
shop_data = shop_data.drop(shop_data_nulls)

# convert ctime response rate to string
shop_data['response_time'] = shop_data['response_time']. \
    apply(lambda time: ctime(time))

# get the timestamp using string selector
shop_data['response_time'] = shop_data['response_time']. \
    apply(lambda time_string: time_string[10:-5])

"""**RATING STAR**"""

# round rating star to two decimal places
shop_data['rating_star'] = shop_data.rating_star. \
    apply(lambda rating: round(rating, 2))

"""**SPLIT CTIME**"""

# split data
shop_data['join_month'] = shop_data['ctime'].dt.month_name()
shop_data['join_day'] = shop_data['ctime'].dt.day
shop_data['join_year'] = shop_data['ctime'].dt.year
shop_data = shop_data.drop(columns='ctime')

# re-arrange shop_data columns
shop_data = shop_data[
    [
        'shopid',
        'name',
        'join_month',
        'join_day',
        'join_year',
        'item_count',
        'follower_count',
        'response_time',
        'response_rate',
        'shop_location',
        'rating_bad',
        'rating_good',
        'rating_normal',
        'rating_star',
        'is_shopee_verified',
        'is_official_shop',
    ]
]
# shopid as dataframe index
shop_data = shop_data.set_index('shopid')

# output file
print('File Exported')
shop_data.to_csv(OUTPUT_FILEPATH + f'{df.time()}-shop_data.csv')
